{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 6.4,
  "eval_steps": 500,
  "global_step": 400,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.016,
      "grad_norm": 144.59445190429688,
      "learning_rate": 6.6666666666666675e-06,
      "logits/chosen": -112.52534484863281,
      "logits/rejected": -113.74095916748047,
      "logps/chosen": -198.39736938476562,
      "logps/rejected": -155.14645385742188,
      "loss": 2.7726,
      "rewards/accuracies": 0.0,
      "rewards/chosen": 0.0,
      "rewards/margins": 0.0,
      "rewards/rejected": 0.0,
      "step": 1
    },
    {
      "epoch": 0.08,
      "grad_norm": 106.10000610351562,
      "learning_rate": 3.3333333333333335e-05,
      "logits/chosen": -109.92623901367188,
      "logits/rejected": -112.8022232055664,
      "logps/chosen": -181.2461700439453,
      "logps/rejected": -149.65936279296875,
      "loss": 2.8407,
      "rewards/accuracies": 0.375,
      "rewards/chosen": -0.038221292197704315,
      "rewards/margins": 0.01317581906914711,
      "rewards/rejected": -0.051397114992141724,
      "step": 5
    },
    {
      "epoch": 0.16,
      "grad_norm": 150.6094207763672,
      "learning_rate": 6.666666666666667e-05,
      "logits/chosen": -108.08451080322266,
      "logits/rejected": -109.73883056640625,
      "logps/chosen": -181.13284301757812,
      "logps/rejected": -168.0101776123047,
      "loss": 3.4852,
      "rewards/accuracies": 0.5249999761581421,
      "rewards/chosen": -0.6757805347442627,
      "rewards/margins": 0.145155668258667,
      "rewards/rejected": -0.8209362030029297,
      "step": 10
    },
    {
      "epoch": 0.24,
      "grad_norm": 142.6805877685547,
      "learning_rate": 0.0001,
      "logits/chosen": -106.42771911621094,
      "logits/rejected": -108.5204086303711,
      "logps/chosen": -208.9216766357422,
      "logps/rejected": -199.83706665039062,
      "loss": 4.0554,
      "rewards/accuracies": 0.5375000238418579,
      "rewards/chosen": -2.8598856925964355,
      "rewards/margins": 0.3957647681236267,
      "rewards/rejected": -3.255650281906128,
      "step": 15
    },
    {
      "epoch": 0.32,
      "grad_norm": 132.47909545898438,
      "learning_rate": 0.00013333333333333334,
      "logits/chosen": -91.98088836669922,
      "logits/rejected": -94.92903137207031,
      "logps/chosen": -196.23150634765625,
      "logps/rejected": -161.7775421142578,
      "loss": 5.7767,
      "rewards/accuracies": 0.4124999940395355,
      "rewards/chosen": -2.6649508476257324,
      "rewards/margins": -0.45270705223083496,
      "rewards/rejected": -2.2122440338134766,
      "step": 20
    },
    {
      "epoch": 0.4,
      "grad_norm": 110.52938842773438,
      "learning_rate": 0.00016666666666666666,
      "logits/chosen": -74.22113037109375,
      "logits/rejected": -76.46754455566406,
      "logps/chosen": -206.2620086669922,
      "logps/rejected": -198.47938537597656,
      "loss": 4.4753,
      "rewards/accuracies": 0.574999988079071,
      "rewards/chosen": -3.4074902534484863,
      "rewards/margins": 0.49836692214012146,
      "rewards/rejected": -3.9058570861816406,
      "step": 25
    },
    {
      "epoch": 0.48,
      "grad_norm": 142.3990936279297,
      "learning_rate": 0.0002,
      "logits/chosen": -72.36393737792969,
      "logits/rejected": -73.23646545410156,
      "logps/chosen": -222.74441528320312,
      "logps/rejected": -212.60177612304688,
      "loss": 5.8389,
      "rewards/accuracies": 0.5375000238418579,
      "rewards/chosen": -3.4159018993377686,
      "rewards/margins": -0.07399173080921173,
      "rewards/rejected": -3.341909885406494,
      "step": 30
    },
    {
      "epoch": 0.56,
      "grad_norm": 92.54605865478516,
      "learning_rate": 0.00023333333333333333,
      "logits/chosen": -50.88390350341797,
      "logits/rejected": -51.17560577392578,
      "logps/chosen": -202.32432556152344,
      "logps/rejected": -195.00184631347656,
      "loss": 6.3534,
      "rewards/accuracies": 0.42500001192092896,
      "rewards/chosen": -4.3788161277771,
      "rewards/margins": -0.047719307243824005,
      "rewards/rejected": -4.33109712600708,
      "step": 35
    },
    {
      "epoch": 0.64,
      "grad_norm": 77.72635650634766,
      "learning_rate": 0.0002666666666666667,
      "logits/chosen": -51.90740203857422,
      "logits/rejected": -52.359107971191406,
      "logps/chosen": -218.3258056640625,
      "logps/rejected": -198.1849822998047,
      "loss": 5.7016,
      "rewards/accuracies": 0.4625000059604645,
      "rewards/chosen": -4.953216075897217,
      "rewards/margins": -0.16668662428855896,
      "rewards/rejected": -4.786529541015625,
      "step": 40
    },
    {
      "epoch": 0.72,
      "grad_norm": 51.29390335083008,
      "learning_rate": 0.0003,
      "logits/chosen": -45.59596633911133,
      "logits/rejected": -47.47968292236328,
      "logps/chosen": -260.8543395996094,
      "logps/rejected": -231.47109985351562,
      "loss": 8.4419,
      "rewards/accuracies": 0.38749998807907104,
      "rewards/chosen": -7.484105110168457,
      "rewards/margins": -0.6127064228057861,
      "rewards/rejected": -6.87139892578125,
      "step": 45
    },
    {
      "epoch": 0.8,
      "grad_norm": 93.93598937988281,
      "learning_rate": 0.0003333333333333333,
      "logits/chosen": -30.410964965820312,
      "logits/rejected": -30.904766082763672,
      "logps/chosen": -228.41848754882812,
      "logps/rejected": -202.49139404296875,
      "loss": 6.4592,
      "rewards/accuracies": 0.4375,
      "rewards/chosen": -7.1869001388549805,
      "rewards/margins": 0.18571257591247559,
      "rewards/rejected": -7.372613430023193,
      "step": 50
    },
    {
      "epoch": 0.88,
      "grad_norm": 67.98489379882812,
      "learning_rate": 0.00036666666666666667,
      "logits/chosen": -41.74553680419922,
      "logits/rejected": -43.02130126953125,
      "logps/chosen": -264.5958251953125,
      "logps/rejected": -257.0113220214844,
      "loss": 11.7356,
      "rewards/accuracies": 0.4749999940395355,
      "rewards/chosen": -10.108846664428711,
      "rewards/margins": -0.47985562682151794,
      "rewards/rejected": -9.628992080688477,
      "step": 55
    },
    {
      "epoch": 0.96,
      "grad_norm": 111.62051391601562,
      "learning_rate": 0.0004,
      "logits/chosen": -47.793479919433594,
      "logits/rejected": -50.617027282714844,
      "logps/chosen": -254.7233428955078,
      "logps/rejected": -238.96560668945312,
      "loss": 7.6577,
      "rewards/accuracies": 0.48750001192092896,
      "rewards/chosen": -8.00078010559082,
      "rewards/margins": -0.25796645879745483,
      "rewards/rejected": -7.742812156677246,
      "step": 60
    },
    {
      "epoch": 1.04,
      "grad_norm": 43.993587493896484,
      "learning_rate": 0.00043333333333333337,
      "logits/chosen": -25.2839298248291,
      "logits/rejected": -25.53082275390625,
      "logps/chosen": -290.53509521484375,
      "logps/rejected": -260.6938171386719,
      "loss": 6.0551,
      "rewards/accuracies": 0.5,
      "rewards/chosen": -9.798622131347656,
      "rewards/margins": 1.9126367568969727,
      "rewards/rejected": -11.711257934570312,
      "step": 65
    },
    {
      "epoch": 1.12,
      "grad_norm": 40.17414474487305,
      "learning_rate": 0.00046666666666666666,
      "logits/chosen": -43.25299835205078,
      "logits/rejected": -45.078651428222656,
      "logps/chosen": -235.1465606689453,
      "logps/rejected": -253.70083618164062,
      "loss": 3.3599,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -7.758530616760254,
      "rewards/margins": 4.088992595672607,
      "rewards/rejected": -11.84752368927002,
      "step": 70
    },
    {
      "epoch": 1.2,
      "grad_norm": 44.863677978515625,
      "learning_rate": 0.0005,
      "logits/chosen": -42.255531311035156,
      "logits/rejected": -45.02709197998047,
      "logps/chosen": -225.59555053710938,
      "logps/rejected": -277.0581970214844,
      "loss": 2.7257,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -6.870046138763428,
      "rewards/margins": 5.665102481842041,
      "rewards/rejected": -12.535149574279785,
      "step": 75
    },
    {
      "epoch": 1.28,
      "grad_norm": 25.8902530670166,
      "learning_rate": 0.0005333333333333334,
      "logits/chosen": -34.618717193603516,
      "logits/rejected": -36.195411682128906,
      "logps/chosen": -273.29449462890625,
      "logps/rejected": -287.86102294921875,
      "loss": 3.3962,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -9.451543807983398,
      "rewards/margins": 3.4964663982391357,
      "rewards/rejected": -12.94800853729248,
      "step": 80
    },
    {
      "epoch": 1.3599999999999999,
      "grad_norm": 54.61989974975586,
      "learning_rate": 0.0005666666666666667,
      "logits/chosen": -37.45909118652344,
      "logits/rejected": -38.61543273925781,
      "logps/chosen": -263.95770263671875,
      "logps/rejected": -270.2968444824219,
      "loss": 6.0986,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": -8.566729545593262,
      "rewards/margins": 2.651076555252075,
      "rewards/rejected": -11.217805862426758,
      "step": 85
    },
    {
      "epoch": 1.44,
      "grad_norm": 42.291664123535156,
      "learning_rate": 0.0006,
      "logits/chosen": -36.091339111328125,
      "logits/rejected": -36.73868179321289,
      "logps/chosen": -234.83834838867188,
      "logps/rejected": -283.28936767578125,
      "loss": 4.4993,
      "rewards/accuracies": 0.675000011920929,
      "rewards/chosen": -7.5843987464904785,
      "rewards/margins": 4.118719577789307,
      "rewards/rejected": -11.703118324279785,
      "step": 90
    },
    {
      "epoch": 1.52,
      "grad_norm": 67.2748031616211,
      "learning_rate": 0.0006333333333333333,
      "logits/chosen": -24.159320831298828,
      "logits/rejected": -24.151004791259766,
      "logps/chosen": -312.13885498046875,
      "logps/rejected": -312.21832275390625,
      "loss": 9.5517,
      "rewards/accuracies": 0.574999988079071,
      "rewards/chosen": -12.423589706420898,
      "rewards/margins": 1.6536039113998413,
      "rewards/rejected": -14.077192306518555,
      "step": 95
    },
    {
      "epoch": 1.6,
      "grad_norm": 71.91646575927734,
      "learning_rate": 0.0006666666666666666,
      "logits/chosen": -26.575769424438477,
      "logits/rejected": -27.168685913085938,
      "logps/chosen": -308.6994934082031,
      "logps/rejected": -306.29962158203125,
      "loss": 6.8268,
      "rewards/accuracies": 0.5874999761581421,
      "rewards/chosen": -12.792274475097656,
      "rewards/margins": 2.3526058197021484,
      "rewards/rejected": -15.144880294799805,
      "step": 100
    },
    {
      "epoch": 1.6800000000000002,
      "grad_norm": 24.640283584594727,
      "learning_rate": 0.0007,
      "logits/chosen": -26.999340057373047,
      "logits/rejected": -28.542129516601562,
      "logps/chosen": -243.3937530517578,
      "logps/rejected": -256.46722412109375,
      "loss": 5.6286,
      "rewards/accuracies": 0.6499999761581421,
      "rewards/chosen": -10.05714225769043,
      "rewards/margins": 2.0074660778045654,
      "rewards/rejected": -12.064607620239258,
      "step": 105
    },
    {
      "epoch": 1.76,
      "grad_norm": 28.71625328063965,
      "learning_rate": 0.0007333333333333333,
      "logits/chosen": -24.19349479675293,
      "logits/rejected": -25.602375030517578,
      "logps/chosen": -275.98358154296875,
      "logps/rejected": -270.05548095703125,
      "loss": 6.3555,
      "rewards/accuracies": 0.637499988079071,
      "rewards/chosen": -10.094856262207031,
      "rewards/margins": 2.175767660140991,
      "rewards/rejected": -12.270625114440918,
      "step": 110
    },
    {
      "epoch": 1.8399999999999999,
      "grad_norm": 62.18623352050781,
      "learning_rate": 0.0007666666666666667,
      "logits/chosen": -30.35226058959961,
      "logits/rejected": -32.52098846435547,
      "logps/chosen": -393.41400146484375,
      "logps/rejected": -400.6966247558594,
      "loss": 18.0597,
      "rewards/accuracies": 0.625,
      "rewards/chosen": -21.924274444580078,
      "rewards/margins": 2.6148908138275146,
      "rewards/rejected": -24.53916358947754,
      "step": 115
    },
    {
      "epoch": 1.92,
      "grad_norm": 94.74333953857422,
      "learning_rate": 0.0008,
      "logits/chosen": -23.302528381347656,
      "logits/rejected": -24.261709213256836,
      "logps/chosen": -309.13043212890625,
      "logps/rejected": -322.6395568847656,
      "loss": 6.2799,
      "rewards/accuracies": 0.6875,
      "rewards/chosen": -13.155001640319824,
      "rewards/margins": 2.7758007049560547,
      "rewards/rejected": -15.930804252624512,
      "step": 120
    },
    {
      "epoch": 2.0,
      "grad_norm": 51.70185089111328,
      "learning_rate": 0.0008333333333333334,
      "logits/chosen": -29.39278793334961,
      "logits/rejected": -28.71059799194336,
      "logps/chosen": -383.8732604980469,
      "logps/rejected": -383.1698913574219,
      "loss": 10.5035,
      "rewards/accuracies": 0.637499988079071,
      "rewards/chosen": -18.762479782104492,
      "rewards/margins": 2.4991188049316406,
      "rewards/rejected": -21.2615966796875,
      "step": 125
    },
    {
      "epoch": 2.08,
      "grad_norm": 119.11367797851562,
      "learning_rate": 0.0008666666666666667,
      "logits/chosen": -23.34145164489746,
      "logits/rejected": -24.569232940673828,
      "logps/chosen": -348.18572998046875,
      "logps/rejected": -359.4615783691406,
      "loss": 5.6087,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -15.046747207641602,
      "rewards/margins": 4.6801557540893555,
      "rewards/rejected": -19.72690200805664,
      "step": 130
    },
    {
      "epoch": 2.16,
      "grad_norm": 87.9529037475586,
      "learning_rate": 0.0009000000000000001,
      "logits/chosen": -33.711307525634766,
      "logits/rejected": -35.2379264831543,
      "logps/chosen": -321.1664733886719,
      "logps/rejected": -381.90673828125,
      "loss": 5.9161,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -15.276723861694336,
      "rewards/margins": 6.643819332122803,
      "rewards/rejected": -21.920543670654297,
      "step": 135
    },
    {
      "epoch": 2.24,
      "grad_norm": 26.310701370239258,
      "learning_rate": 0.0009333333333333333,
      "logits/chosen": -22.5150146484375,
      "logits/rejected": -21.75452423095703,
      "logps/chosen": -281.1707763671875,
      "logps/rejected": -332.102294921875,
      "loss": 5.6148,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -12.357604026794434,
      "rewards/margins": 4.622220993041992,
      "rewards/rejected": -16.979827880859375,
      "step": 140
    },
    {
      "epoch": 2.32,
      "grad_norm": 36.95581817626953,
      "learning_rate": 0.0009666666666666667,
      "logits/chosen": -23.054447174072266,
      "logits/rejected": -24.185394287109375,
      "logps/chosen": -317.2909240722656,
      "logps/rejected": -364.11212158203125,
      "loss": 2.6723,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -15.16650104522705,
      "rewards/margins": 6.687043190002441,
      "rewards/rejected": -21.85354232788086,
      "step": 145
    },
    {
      "epoch": 2.4,
      "grad_norm": 55.363975524902344,
      "learning_rate": 0.001,
      "logits/chosen": -23.788442611694336,
      "logits/rejected": -25.050704956054688,
      "logps/chosen": -322.32464599609375,
      "logps/rejected": -383.2778625488281,
      "loss": 3.9455,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -15.510955810546875,
      "rewards/margins": 6.860418796539307,
      "rewards/rejected": -22.37137222290039,
      "step": 150
    },
    {
      "epoch": 2.48,
      "grad_norm": 64.34445190429688,
      "learning_rate": 0.00098,
      "logits/chosen": -27.711008071899414,
      "logits/rejected": -28.292552947998047,
      "logps/chosen": -340.6155090332031,
      "logps/rejected": -379.4947204589844,
      "loss": 4.6258,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -16.670207977294922,
      "rewards/margins": 4.70647668838501,
      "rewards/rejected": -21.376684188842773,
      "step": 155
    },
    {
      "epoch": 2.56,
      "grad_norm": 33.023433685302734,
      "learning_rate": 0.00096,
      "logits/chosen": -21.007320404052734,
      "logits/rejected": -21.76150894165039,
      "logps/chosen": -320.10797119140625,
      "logps/rejected": -328.0858154296875,
      "loss": 7.8554,
      "rewards/accuracies": 0.6499999761581421,
      "rewards/chosen": -15.730363845825195,
      "rewards/margins": 2.981480121612549,
      "rewards/rejected": -18.711843490600586,
      "step": 160
    },
    {
      "epoch": 2.64,
      "grad_norm": 51.98725509643555,
      "learning_rate": 0.00094,
      "logits/chosen": -17.975093841552734,
      "logits/rejected": -20.862314224243164,
      "logps/chosen": -339.50958251953125,
      "logps/rejected": -349.79248046875,
      "loss": 4.9328,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -14.884943008422852,
      "rewards/margins": 5.640151023864746,
      "rewards/rejected": -20.525094985961914,
      "step": 165
    },
    {
      "epoch": 2.7199999999999998,
      "grad_norm": 134.8293914794922,
      "learning_rate": 0.00092,
      "logits/chosen": -21.967893600463867,
      "logits/rejected": -23.73501968383789,
      "logps/chosen": -383.7297058105469,
      "logps/rejected": -381.5199279785156,
      "loss": 9.3418,
      "rewards/accuracies": 0.637499988079071,
      "rewards/chosen": -20.372478485107422,
      "rewards/margins": 3.602604627609253,
      "rewards/rejected": -23.975088119506836,
      "step": 170
    },
    {
      "epoch": 2.8,
      "grad_norm": 30.77348518371582,
      "learning_rate": 0.0009000000000000001,
      "logits/chosen": -21.175853729248047,
      "logits/rejected": -21.613006591796875,
      "logps/chosen": -312.0264892578125,
      "logps/rejected": -325.07037353515625,
      "loss": 6.7607,
      "rewards/accuracies": 0.6875,
      "rewards/chosen": -15.550443649291992,
      "rewards/margins": 2.670531749725342,
      "rewards/rejected": -18.22097396850586,
      "step": 175
    },
    {
      "epoch": 2.88,
      "grad_norm": 0.4212893843650818,
      "learning_rate": 0.00088,
      "logits/chosen": -36.431434631347656,
      "logits/rejected": -38.14653778076172,
      "logps/chosen": -331.8031005859375,
      "logps/rejected": -367.8175964355469,
      "loss": 3.4521,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -16.162372589111328,
      "rewards/margins": 5.566772937774658,
      "rewards/rejected": -21.729145050048828,
      "step": 180
    },
    {
      "epoch": 2.96,
      "grad_norm": 38.285335540771484,
      "learning_rate": 0.00086,
      "logits/chosen": -25.167491912841797,
      "logits/rejected": -26.83840560913086,
      "logps/chosen": -331.65313720703125,
      "logps/rejected": -364.71319580078125,
      "loss": 4.5248,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -15.420309066772461,
      "rewards/margins": 3.829836368560791,
      "rewards/rejected": -19.25014877319336,
      "step": 185
    },
    {
      "epoch": 3.04,
      "grad_norm": 76.27729034423828,
      "learning_rate": 0.00084,
      "logits/chosen": -26.91008949279785,
      "logits/rejected": -28.80008316040039,
      "logps/chosen": -356.4593811035156,
      "logps/rejected": -429.36163330078125,
      "loss": 2.3199,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -17.079294204711914,
      "rewards/margins": 8.059300422668457,
      "rewards/rejected": -25.138595581054688,
      "step": 190
    },
    {
      "epoch": 3.12,
      "grad_norm": 52.073787689208984,
      "learning_rate": 0.00082,
      "logits/chosen": -31.165115356445312,
      "logits/rejected": -33.37068557739258,
      "logps/chosen": -336.0461120605469,
      "logps/rejected": -447.69036865234375,
      "loss": 1.7463,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -16.193588256835938,
      "rewards/margins": 12.858380317687988,
      "rewards/rejected": -29.051965713500977,
      "step": 195
    },
    {
      "epoch": 3.2,
      "grad_norm": 23.54346466064453,
      "learning_rate": 0.0008,
      "logits/chosen": -25.19098472595215,
      "logits/rejected": -26.819625854492188,
      "logps/chosen": -327.2007141113281,
      "logps/rejected": -398.8634338378906,
      "loss": 1.2883,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -16.158824920654297,
      "rewards/margins": 8.713800430297852,
      "rewards/rejected": -24.872623443603516,
      "step": 200
    },
    {
      "epoch": 3.2800000000000002,
      "grad_norm": 40.1850700378418,
      "learning_rate": 0.0007800000000000001,
      "logits/chosen": -34.0532112121582,
      "logits/rejected": -39.82744216918945,
      "logps/chosen": -367.2698669433594,
      "logps/rejected": -415.1390686035156,
      "loss": 1.3172,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -18.809917449951172,
      "rewards/margins": 8.480944633483887,
      "rewards/rejected": -27.29085922241211,
      "step": 205
    },
    {
      "epoch": 3.36,
      "grad_norm": 10.015588760375977,
      "learning_rate": 0.00076,
      "logits/chosen": -31.756393432617188,
      "logits/rejected": -34.87803268432617,
      "logps/chosen": -317.798828125,
      "logps/rejected": -403.8172912597656,
      "loss": 1.232,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -14.89799690246582,
      "rewards/margins": 9.795026779174805,
      "rewards/rejected": -24.69301986694336,
      "step": 210
    },
    {
      "epoch": 3.44,
      "grad_norm": 39.70294952392578,
      "learning_rate": 0.00074,
      "logits/chosen": -22.56224822998047,
      "logits/rejected": -28.550418853759766,
      "logps/chosen": -293.15802001953125,
      "logps/rejected": -368.6797790527344,
      "loss": 1.357,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -12.230435371398926,
      "rewards/margins": 10.167680740356445,
      "rewards/rejected": -22.398113250732422,
      "step": 215
    },
    {
      "epoch": 3.52,
      "grad_norm": 5.104374408721924,
      "learning_rate": 0.0007199999999999999,
      "logits/chosen": -21.639240264892578,
      "logits/rejected": -22.90508270263672,
      "logps/chosen": -295.1517028808594,
      "logps/rejected": -414.9022521972656,
      "loss": 1.523,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -13.982023239135742,
      "rewards/margins": 10.798033714294434,
      "rewards/rejected": -24.780057907104492,
      "step": 220
    },
    {
      "epoch": 3.6,
      "grad_norm": 13.988702774047852,
      "learning_rate": 0.0007,
      "logits/chosen": -33.69394302368164,
      "logits/rejected": -36.34782409667969,
      "logps/chosen": -315.9014892578125,
      "logps/rejected": -402.21014404296875,
      "loss": 1.1842,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -15.659281730651855,
      "rewards/margins": 10.713947296142578,
      "rewards/rejected": -26.37322998046875,
      "step": 225
    },
    {
      "epoch": 3.68,
      "grad_norm": 19.94361114501953,
      "learning_rate": 0.00068,
      "logits/chosen": -30.117843627929688,
      "logits/rejected": -31.640132904052734,
      "logps/chosen": -350.02545166015625,
      "logps/rejected": -452.3787536621094,
      "loss": 0.695,
      "rewards/accuracies": 0.925000011920929,
      "rewards/chosen": -14.996088027954102,
      "rewards/margins": 13.004260063171387,
      "rewards/rejected": -28.000350952148438,
      "step": 230
    },
    {
      "epoch": 3.76,
      "grad_norm": 10.566052436828613,
      "learning_rate": 0.00066,
      "logits/chosen": -35.20752716064453,
      "logits/rejected": -37.359344482421875,
      "logps/chosen": -309.732421875,
      "logps/rejected": -391.83416748046875,
      "loss": 1.2334,
      "rewards/accuracies": 0.925000011920929,
      "rewards/chosen": -12.627914428710938,
      "rewards/margins": 10.83227252960205,
      "rewards/rejected": -23.460186004638672,
      "step": 235
    },
    {
      "epoch": 3.84,
      "grad_norm": 8.22770881652832,
      "learning_rate": 0.00064,
      "logits/chosen": -30.880462646484375,
      "logits/rejected": -33.146202087402344,
      "logps/chosen": -317.1761474609375,
      "logps/rejected": -417.67645263671875,
      "loss": 0.2878,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -14.055383682250977,
      "rewards/margins": 11.657742500305176,
      "rewards/rejected": -25.713125228881836,
      "step": 240
    },
    {
      "epoch": 3.92,
      "grad_norm": 36.48982620239258,
      "learning_rate": 0.00062,
      "logits/chosen": -32.401832580566406,
      "logits/rejected": -36.337398529052734,
      "logps/chosen": -318.3536376953125,
      "logps/rejected": -412.357666015625,
      "loss": 0.9988,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -14.964756965637207,
      "rewards/margins": 9.9431734085083,
      "rewards/rejected": -24.907930374145508,
      "step": 245
    },
    {
      "epoch": 4.0,
      "grad_norm": 15.950461387634277,
      "learning_rate": 0.0006,
      "logits/chosen": -24.949167251586914,
      "logits/rejected": -28.847497940063477,
      "logps/chosen": -340.5894470214844,
      "logps/rejected": -413.84576416015625,
      "loss": 1.3634,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -16.109722137451172,
      "rewards/margins": 10.718637466430664,
      "rewards/rejected": -26.828359603881836,
      "step": 250
    },
    {
      "epoch": 4.08,
      "grad_norm": 24.604686737060547,
      "learning_rate": 0.00058,
      "logits/chosen": -30.87514305114746,
      "logits/rejected": -33.54703140258789,
      "logps/chosen": -320.4412536621094,
      "logps/rejected": -440.2444763183594,
      "loss": 0.4697,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -14.36482048034668,
      "rewards/margins": 14.487098693847656,
      "rewards/rejected": -28.8519229888916,
      "step": 255
    },
    {
      "epoch": 4.16,
      "grad_norm": 0.17688778042793274,
      "learning_rate": 0.0005600000000000001,
      "logits/chosen": -29.835535049438477,
      "logits/rejected": -33.27260208129883,
      "logps/chosen": -287.9786071777344,
      "logps/rejected": -378.9293212890625,
      "loss": 0.1889,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -12.105281829833984,
      "rewards/margins": 11.783926010131836,
      "rewards/rejected": -23.889209747314453,
      "step": 260
    },
    {
      "epoch": 4.24,
      "grad_norm": 1.527716040611267,
      "learning_rate": 0.00054,
      "logits/chosen": -37.190940856933594,
      "logits/rejected": -40.322391510009766,
      "logps/chosen": -307.35498046875,
      "logps/rejected": -422.5333557128906,
      "loss": 0.3102,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -13.648971557617188,
      "rewards/margins": 12.9469633102417,
      "rewards/rejected": -26.595937728881836,
      "step": 265
    },
    {
      "epoch": 4.32,
      "grad_norm": 23.206764221191406,
      "learning_rate": 0.0005200000000000001,
      "logits/chosen": -35.056575775146484,
      "logits/rejected": -38.14623260498047,
      "logps/chosen": -321.1892395019531,
      "logps/rejected": -484.271484375,
      "loss": 0.6069,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -15.01756477355957,
      "rewards/margins": 16.14518928527832,
      "rewards/rejected": -31.162755966186523,
      "step": 270
    },
    {
      "epoch": 4.4,
      "grad_norm": 1.33095383644104,
      "learning_rate": 0.0005,
      "logits/chosen": -29.856891632080078,
      "logits/rejected": -32.41973876953125,
      "logps/chosen": -279.11212158203125,
      "logps/rejected": -395.37933349609375,
      "loss": 0.2767,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -11.445650100708008,
      "rewards/margins": 13.623804092407227,
      "rewards/rejected": -25.069454193115234,
      "step": 275
    },
    {
      "epoch": 4.48,
      "grad_norm": 6.537149906158447,
      "learning_rate": 0.00048,
      "logits/chosen": -24.901958465576172,
      "logits/rejected": -27.052867889404297,
      "logps/chosen": -303.95782470703125,
      "logps/rejected": -426.19873046875,
      "loss": 0.0621,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -11.336045265197754,
      "rewards/margins": 15.507612228393555,
      "rewards/rejected": -26.84365463256836,
      "step": 280
    },
    {
      "epoch": 4.5600000000000005,
      "grad_norm": 1.3202323913574219,
      "learning_rate": 0.00046,
      "logits/chosen": -24.15021514892578,
      "logits/rejected": -26.03336524963379,
      "logps/chosen": -258.48382568359375,
      "logps/rejected": -381.99365234375,
      "loss": 0.1858,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -10.569583892822266,
      "rewards/margins": 13.019994735717773,
      "rewards/rejected": -23.58957862854004,
      "step": 285
    },
    {
      "epoch": 4.64,
      "grad_norm": 2.21816349029541,
      "learning_rate": 0.00044,
      "logits/chosen": -28.519577026367188,
      "logits/rejected": -30.086360931396484,
      "logps/chosen": -315.083251953125,
      "logps/rejected": -439.87847900390625,
      "loss": 0.053,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -13.03265380859375,
      "rewards/margins": 13.598040580749512,
      "rewards/rejected": -26.630695343017578,
      "step": 290
    },
    {
      "epoch": 4.72,
      "grad_norm": 5.479516506195068,
      "learning_rate": 0.00042,
      "logits/chosen": -39.00447463989258,
      "logits/rejected": -43.10707473754883,
      "logps/chosen": -315.8492126464844,
      "logps/rejected": -453.07354736328125,
      "loss": 0.0848,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -14.210832595825195,
      "rewards/margins": 14.942407608032227,
      "rewards/rejected": -29.153240203857422,
      "step": 295
    },
    {
      "epoch": 4.8,
      "grad_norm": 0.021620802581310272,
      "learning_rate": 0.0004,
      "logits/chosen": -39.055999755859375,
      "logits/rejected": -45.51787185668945,
      "logps/chosen": -335.933837890625,
      "logps/rejected": -476.7845764160156,
      "loss": 0.6367,
      "rewards/accuracies": 0.925000011920929,
      "rewards/chosen": -14.913763046264648,
      "rewards/margins": 17.491146087646484,
      "rewards/rejected": -32.4049072265625,
      "step": 300
    },
    {
      "epoch": 4.88,
      "grad_norm": 4.172174453735352,
      "learning_rate": 0.00038,
      "logits/chosen": -31.454315185546875,
      "logits/rejected": -35.69916534423828,
      "logps/chosen": -312.9558410644531,
      "logps/rejected": -452.73876953125,
      "loss": 0.1349,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -13.112629890441895,
      "rewards/margins": 16.594802856445312,
      "rewards/rejected": -29.70743179321289,
      "step": 305
    },
    {
      "epoch": 4.96,
      "grad_norm": 53.32986831665039,
      "learning_rate": 0.00035999999999999997,
      "logits/chosen": -32.14215850830078,
      "logits/rejected": -36.01458740234375,
      "logps/chosen": -325.88653564453125,
      "logps/rejected": -468.228515625,
      "loss": 0.4501,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -16.777801513671875,
      "rewards/margins": 15.535165786743164,
      "rewards/rejected": -32.312965393066406,
      "step": 310
    },
    {
      "epoch": 5.04,
      "grad_norm": 4.5871734619140625,
      "learning_rate": 0.00034,
      "logits/chosen": -36.115726470947266,
      "logits/rejected": -39.014564514160156,
      "logps/chosen": -289.0554504394531,
      "logps/rejected": -435.2798767089844,
      "loss": 0.3301,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -13.739405632019043,
      "rewards/margins": 15.732568740844727,
      "rewards/rejected": -29.471973419189453,
      "step": 315
    },
    {
      "epoch": 5.12,
      "grad_norm": 0.704809308052063,
      "learning_rate": 0.00032,
      "logits/chosen": -31.364978790283203,
      "logits/rejected": -37.881805419921875,
      "logps/chosen": -280.5862731933594,
      "logps/rejected": -427.06439208984375,
      "loss": 0.0498,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -11.194425582885742,
      "rewards/margins": 17.460586547851562,
      "rewards/rejected": -28.655014038085938,
      "step": 320
    },
    {
      "epoch": 5.2,
      "grad_norm": 0.07807431370019913,
      "learning_rate": 0.0003,
      "logits/chosen": -25.29866600036621,
      "logits/rejected": -29.03607177734375,
      "logps/chosen": -282.47283935546875,
      "logps/rejected": -405.54296875,
      "loss": 0.0464,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -10.597229957580566,
      "rewards/margins": 15.372385025024414,
      "rewards/rejected": -25.969614028930664,
      "step": 325
    },
    {
      "epoch": 5.28,
      "grad_norm": 0.07833075523376465,
      "learning_rate": 0.00028000000000000003,
      "logits/chosen": -25.170082092285156,
      "logits/rejected": -30.139841079711914,
      "logps/chosen": -273.8684387207031,
      "logps/rejected": -449.2967834472656,
      "loss": 0.0372,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -11.119236946105957,
      "rewards/margins": 18.05154037475586,
      "rewards/rejected": -29.170780181884766,
      "step": 330
    },
    {
      "epoch": 5.36,
      "grad_norm": 0.07741648703813553,
      "learning_rate": 0.00026000000000000003,
      "logits/chosen": -24.83968734741211,
      "logits/rejected": -28.00441551208496,
      "logps/chosen": -300.44024658203125,
      "logps/rejected": -438.73486328125,
      "loss": 0.0408,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -11.459502220153809,
      "rewards/margins": 16.192401885986328,
      "rewards/rejected": -27.651906967163086,
      "step": 335
    },
    {
      "epoch": 5.44,
      "grad_norm": 0.025881445035338402,
      "learning_rate": 0.00024,
      "logits/chosen": -23.000211715698242,
      "logits/rejected": -24.370420455932617,
      "logps/chosen": -294.8017578125,
      "logps/rejected": -473.6927795410156,
      "loss": 0.0281,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -11.506959915161133,
      "rewards/margins": 17.75509262084961,
      "rewards/rejected": -29.262054443359375,
      "step": 340
    },
    {
      "epoch": 5.52,
      "grad_norm": 17.908039093017578,
      "learning_rate": 0.00022,
      "logits/chosen": -32.405372619628906,
      "logits/rejected": -37.705589294433594,
      "logps/chosen": -270.4505920410156,
      "logps/rejected": -446.02984619140625,
      "loss": 0.3053,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -11.974686622619629,
      "rewards/margins": 17.85849952697754,
      "rewards/rejected": -29.833187103271484,
      "step": 345
    },
    {
      "epoch": 5.6,
      "grad_norm": 0.7394393682479858,
      "learning_rate": 0.0002,
      "logits/chosen": -24.411096572875977,
      "logits/rejected": -30.070755004882812,
      "logps/chosen": -298.060302734375,
      "logps/rejected": -469.88446044921875,
      "loss": 0.0383,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -10.867536544799805,
      "rewards/margins": 20.037078857421875,
      "rewards/rejected": -30.904621124267578,
      "step": 350
    },
    {
      "epoch": 5.68,
      "grad_norm": 0.07372093945741653,
      "learning_rate": 0.00017999999999999998,
      "logits/chosen": -26.323965072631836,
      "logits/rejected": -29.240280151367188,
      "logps/chosen": -296.4677429199219,
      "logps/rejected": -456.0088806152344,
      "loss": 0.035,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -11.306783676147461,
      "rewards/margins": 18.781970977783203,
      "rewards/rejected": -30.088754653930664,
      "step": 355
    },
    {
      "epoch": 5.76,
      "grad_norm": 0.02923613227903843,
      "learning_rate": 0.00016,
      "logits/chosen": -26.383413314819336,
      "logits/rejected": -30.458730697631836,
      "logps/chosen": -272.8479309082031,
      "logps/rejected": -457.56024169921875,
      "loss": 0.0382,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -11.517533302307129,
      "rewards/margins": 18.31833267211914,
      "rewards/rejected": -29.835865020751953,
      "step": 360
    },
    {
      "epoch": 5.84,
      "grad_norm": 50.64828109741211,
      "learning_rate": 0.00014000000000000001,
      "logits/chosen": -25.364355087280273,
      "logits/rejected": -27.396753311157227,
      "logps/chosen": -301.2370300292969,
      "logps/rejected": -465.155517578125,
      "loss": 0.3337,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -11.121743202209473,
      "rewards/margins": 19.825143814086914,
      "rewards/rejected": -30.946884155273438,
      "step": 365
    },
    {
      "epoch": 5.92,
      "grad_norm": 0.052120234817266464,
      "learning_rate": 0.00012,
      "logits/chosen": -28.018789291381836,
      "logits/rejected": -34.461029052734375,
      "logps/chosen": -283.4514465332031,
      "logps/rejected": -454.3294982910156,
      "loss": 0.0329,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -10.663492202758789,
      "rewards/margins": 20.02602767944336,
      "rewards/rejected": -30.68951988220215,
      "step": 370
    },
    {
      "epoch": 6.0,
      "grad_norm": 0.006942284759134054,
      "learning_rate": 0.0001,
      "logits/chosen": -26.9907169342041,
      "logits/rejected": -31.213491439819336,
      "logps/chosen": -306.8329772949219,
      "logps/rejected": -486.4771423339844,
      "loss": 0.0352,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -12.318830490112305,
      "rewards/margins": 19.100749969482422,
      "rewards/rejected": -31.419586181640625,
      "step": 375
    },
    {
      "epoch": 6.08,
      "grad_norm": 0.0006335835787467659,
      "learning_rate": 8e-05,
      "logits/chosen": -27.889034271240234,
      "logits/rejected": -33.87305450439453,
      "logps/chosen": -273.97686767578125,
      "logps/rejected": -462.92315673828125,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -10.50005054473877,
      "rewards/margins": 19.762670516967773,
      "rewards/rejected": -30.262720108032227,
      "step": 380
    },
    {
      "epoch": 6.16,
      "grad_norm": 0.020274141803383827,
      "learning_rate": 6e-05,
      "logits/chosen": -29.294092178344727,
      "logits/rejected": -33.85376739501953,
      "logps/chosen": -275.4721374511719,
      "logps/rejected": -440.75677490234375,
      "loss": 0.0354,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -10.864978790283203,
      "rewards/margins": 18.027400970458984,
      "rewards/rejected": -28.892379760742188,
      "step": 385
    },
    {
      "epoch": 6.24,
      "grad_norm": 0.007400732021778822,
      "learning_rate": 4e-05,
      "logits/chosen": -27.050607681274414,
      "logits/rejected": -31.926916122436523,
      "logps/chosen": -307.96978759765625,
      "logps/rejected": -504.6958923339844,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -12.11601734161377,
      "rewards/margins": 20.499004364013672,
      "rewards/rejected": -32.615020751953125,
      "step": 390
    },
    {
      "epoch": 6.32,
      "grad_norm": 0.014752174727618694,
      "learning_rate": 2e-05,
      "logits/chosen": -27.841461181640625,
      "logits/rejected": -33.80454635620117,
      "logps/chosen": -275.4468688964844,
      "logps/rejected": -463.47906494140625,
      "loss": 0.0348,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -10.873522758483887,
      "rewards/margins": 20.33605194091797,
      "rewards/rejected": -31.20957374572754,
      "step": 395
    },
    {
      "epoch": 6.4,
      "grad_norm": 0.0006448912317864597,
      "learning_rate": 0.0,
      "logits/chosen": -30.721111297607422,
      "logits/rejected": -32.07780456542969,
      "logps/chosen": -274.125244140625,
      "logps/rejected": -467.3341369628906,
      "loss": 0.0352,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -11.804300308227539,
      "rewards/margins": 18.53557777404785,
      "rewards/rejected": -30.33987808227539,
      "step": 400
    }
  ],
  "logging_steps": 5,
  "max_steps": 400,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 7,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 0.0,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
